{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metallic-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d415dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Specify the path to your JSONL file\n",
    "# jsonl_file_path = \"myy.jsonl\"\n",
    "\n",
    "# # Initialize an empty list to store the data\n",
    "# train_data = []\n",
    "\n",
    "# # Read the data from the JSONL file with the appropriate encoding (e.g., 'utf-8')\n",
    "# with open(jsonl_file_path, \"r\", encoding=\"utf-8\") as jsonl_file:\n",
    "#     for line in jsonl_file:\n",
    "#         data = json.loads(line)\n",
    "#         train_data.append(data)\n",
    "\n",
    "# # Now you have the data in the `train_data` list, and you can format it as needed.\n",
    "\n",
    "\n",
    "# # Now you have the data in the `train_data` list, and you can format it as needed.\n",
    "\n",
    "# # Now you have the data in the `train_data` list, and you can format it as needed.\n",
    "\n",
    "# formatted_data = []\n",
    "\n",
    "# for data in train_data:\n",
    "#     label = data[\"label\"][0]  # Assuming the label is a list with a single element\n",
    "#     provision = data[\"provision\"]\n",
    "#     formatted_data.append((provision, label))\n",
    "\n",
    "# print(formatted_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = \"myy.jsonl\"\n",
    "output_file = \"output5.txt\"\n",
    "\n",
    "# Open the input and output files\n",
    "with open(input_file, \"r\",encoding=\"utf-8\") as infile, open(output_file, \"w\",encoding=\"utf-8\") as outfile:\n",
    "    # Iterate through each line in the JSONLines file\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "        label = data[\"label\"][0]\n",
    "        provision = data[\"provision\"]\n",
    "        result = (provision,label)\n",
    "        \n",
    "        # Write the result to the output file\n",
    "        outfile.write(str(result) + ','+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import json\n",
    "\n",
    "# # Specify the path to your JSONL file\n",
    "# jsonl_file_path = \"myy.jsonl\"\n",
    "\n",
    "# # Initialize an empty list to store the data\n",
    "# train_data = []\n",
    "\n",
    "# # Read the data from the JSONL file with the appropriate encoding (e.g., 'utf-8')\n",
    "# with open(jsonl_file_path, \"r\", encoding=\"utf-8\") as jsonl_file:\n",
    "#     for line in jsonl_file:\n",
    "#         data = json.loads(line)\n",
    "#         train_data.append(data)\n",
    "\n",
    "# # Now you have the data in the `train_data` list, and you can format it as needed.\n",
    "\n",
    "# formatted_data = []\n",
    "\n",
    "# # Formatting the data\n",
    "# for provision, label in train_data:\n",
    "#     formatted_data.append(f\"{label}: {provision}\")\n",
    "\n",
    "# # Specify the path for the new file where you want to write the data\n",
    "# output_file_path = \"formatted_datass.txt\"\n",
    "\n",
    "# # Write the formatted data to the new file\n",
    "# with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "#     for line in formatted_data:\n",
    "#         output_file.write(line + \"\\n\")\n",
    "\n",
    "# print(\"Formatted data has been written to the new file:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4efa9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3069a52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nnjndosfncsodn', 'recitals')\n"
     ]
    }
   ],
   "source": [
    "train_data=[(\n",
    "    'nnjndosfncsodn','recitals'\n",
    ")]\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stunning-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_docs(data):\n",
    "    docs = []\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        if label == \"recitals\":\n",
    "            doc.cats[\"recitals\"] = 1\n",
    "            doc.cats[\"title\"] = 0\n",
    "            doc.cats[\"appendix\"] = 0\n",
    "            doc.cats[\"definitions\"] = 0\n",
    "            doc.cats[\"signatures\"] = 0\n",
    "            doc.cats[\"notices\"] = 0\n",
    "        elif label == \"title\":\n",
    "            doc.cats[\"recitals\"] = 0\n",
    "            doc.cats[\"title\"] = 1\n",
    "            doc.cats[\"appendix\"] = 0\n",
    "            doc.cats[\"definitions\"] = 0\n",
    "            doc.cats[\"signatures\"] = 0\n",
    "            doc.cats[\"notices\"] = 0\n",
    "        elif label==\"definitions\":\n",
    "            doc.cats[\"recitals\"] = 0\n",
    "            doc.cats[\"title\"] = 0\n",
    "            doc.cats[\"appendix\"] = 0\n",
    "            doc.cats[\"definitions\"] = 1\n",
    "            doc.cats[\"signatures\"] = 0\n",
    "            doc.cats[\"notices\"] = 0\n",
    "        elif label==\"signatures\":\n",
    "            doc.cats[\"recitals\"] = 0\n",
    "            doc.cats[\"title\"] = 0\n",
    "            doc.cats[\"appendix\"] = 0\n",
    "            doc.cats[\"definitions\"] = 0\n",
    "            doc.cats[\"signatures\"] = 1\n",
    "            doc.cats[\"notices\"] = 0\n",
    "        elif label==\"notices\":\n",
    "            doc.cats[\"recitals\"] = 0\n",
    "            doc.cats[\"title\"] = 0\n",
    "            doc.cats[\"appendix\"] = 0\n",
    "            doc.cats[\"definitions\"] = 0\n",
    "            doc.cats[\"signatures\"] = 0\n",
    "            doc.cats[\"notices\"] = 1\n",
    "\n",
    "        elif label==\"appendix\":\n",
    "            doc.cats[\"recitals\"] = 0\n",
    "            doc.cats[\"title\"] = 0\n",
    "            doc.cats[\"appendix\"] = 1\n",
    "            doc.cats[\"definitions\"] = 0\n",
    "            doc.cats[\"signatures\"] = 0\n",
    "            doc.cats[\"notices\"] = 0\n",
    "        docs.append(doc)\n",
    "    return (docs)\n",
    "        \n",
    "\n",
    "\n",
    "train_docs = make_docs(train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "successful-hearts",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "clinical-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.1\n",
    "\n",
    "# Calculate the number of samples for validation\n",
    "num_validation_samples = int(len(train_data) * validation_split)\n",
    "\n",
    "# Split train_data into train and valid sets\n",
    "valid_data = train_data[:num_validation_samples]\n",
    "train_data = train_data[num_validation_samples:]\n",
    "num_texts = 500\n",
    "\n",
    "train_docs = make_docs(train_data[:num_texts])\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"./data/train5.spacy\")\n",
    "\n",
    "valid_docs = make_docs(valid_data[:num_texts])\n",
    "doc_bin = DocBin(docs=valid_docs)\n",
    "doc_bin.to_disk(\"./data/valid5.spacy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-roulette",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
